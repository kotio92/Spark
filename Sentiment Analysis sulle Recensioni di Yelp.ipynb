{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis sulle Recensioni di Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **Sentiment Analysis** è il processo di identificazione dell'emozione espressa in un testo, positiva o negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In questo notebook useremo Spark e la sua MLlib per costruire un modello di Sentiment Analysis usando il dataset messo a disposizione da Yelp, una famossisima applicazione che permette di recensire locali e attività commerciali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importazione delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, max, col, year, sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializzazione di Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basic').getOrCreate()\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scarico da Kaggle lo .zip contenente il dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download yelp-dataset/yelp-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estraggo il dataset dal .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.unpack_archive('yelp-dataset.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carico il dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_df = spark.read.json('yelp_academic_dataset_review.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|-MhfebM0QIsKt87iD...|   0|2015-04-15 05:21:16|    0|xQY8N_XvtGbearJ5X...|  2.0|As someone who ha...|     5|OwjRMXRC0KyPrIlcj...|\n",
      "|lbrU8StCq3yDfr-QM...|   0|2013-12-07 03:16:52|    1|UmFMZ8PyXZTY2Qcwz...|  1.0|I am actually hor...|     1|nIJD_7ZXHq-FX8byP...|\n",
      "|HQl28KMwrEKHqhFrr...|   0|2015-12-05 03:18:11|    0|LG2ZaYiOgpr2DK_90...|  5.0|I love Deagan's. ...|     1|V34qejxNsCbcgD8C0...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelp_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esaminiamo questa tabella. Innanzitutto vediamo il numero di righe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora le colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id',\n",
       " 'cool',\n",
       " 'date',\n",
       " 'funny',\n",
       " 'review_id',\n",
       " 'stars',\n",
       " 'text',\n",
       " 'useful',\n",
       " 'user_id']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo ben 9 colonne, che sono:\n",
    "\n",
    "* **user_id**: identificativo del recensore\n",
    "* **business_id**: identificato del business recensito\n",
    "* **review_id**: identificativo della recensione\n",
    "* **text**: testo della recensione\n",
    "* **date**: data della recensione\n",
    "* **stars**: valutazione dell'attività (da 1.0 a 5.0).\n",
    "* **useful**: numero di utenti che hanno segnato la recensione come uile\n",
    "* **cool**: numero degli utenti che hanno segnato la recensione come figa.\n",
    "* **funny**: numero di utenti che hanno segnato la recensione come divertente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelp_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le uniche informazioni che a noi interessano sono il testo e la valutazione, creiamo un nuovo DataFrame con soltanto queste colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = yelp_df.select('text','stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|stars|\n",
      "+--------------------+-----+\n",
      "|As someone who ha...|  2.0|\n",
      "|I am actually hor...|  1.0|\n",
      "|I love Deagan's. ...|  5.0|\n",
      "|Dismal, lukewarm,...|  1.0|\n",
      "|Oh happy day, fin...|  4.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cominciamo creando un modello utilizzando soltanto il 1% del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreviews_df = reviews_df.sample(fraction=0.01, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing del testo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora dobbiamo processare il testo delle recensioni per renderlo un buon input per una modello di machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rimozione della punteggiatura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero una funzione per la rimozione della punteggiatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo la **funzione udf** (User Defined Function - Funzione Definita dall'Utente) per creare una funzione spark partendo da quella che abbiamo definito noi per la rimozione della punteggiatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "funz = udf(lambda s: remove_punct(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fatto questo applichiamo la funzione alla colonna text, per rimuovere la punteggiatura da ogni recensione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreviews_df = subreviews_df.withColumn('text', funz(col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|stars|\n",
      "+--------------------+-----+\n",
      "|I have been here ...|  4.0|\n",
      "|So far one of the...|  5.0|\n",
      "|Came here for hap...|  1.0|\n",
      "|Bad 1st experienc...|  1.0|\n",
      "|So many great thi...|  4.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subreviews_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B: avremmo potuto ottenere lo stesso effetto anche applicando direttamente un **decoratore**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|                text|stars|   remove_punct_text|\n",
      "+--------------------+-----+--------------------+\n",
      "|I have been here ...|  4.0|I have been here ...|\n",
      "|So far one of the...|  5.0|So far one of the...|\n",
      "|Came here for hap...|  1.0|Came here for hap...|\n",
      "|Bad 1st experienc...|  1.0|Bad 1st experienc...|\n",
      "|So many great thi...|  4.0|So many great thi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@udf()\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "subreviews_df.withColumn('remove_punct_text', remove_punct(col('text'))).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora eseguiamo la **Tokenizzazione**, che ci serve per estrarre i Token dal testo, cioè le sue parti costituenti (le parole insomma). Per farlo possiamo usare la classe **Tokenizer** di MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "words_df = tokenizer.transform(subreviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|                text|stars|               words|\n",
      "+--------------------+-----+--------------------+\n",
      "|I have been here ...|  4.0|[i, have, been, h...|\n",
      "|So far one of the...|  5.0|[so, far, one, of...|\n",
      "|Came here for hap...|  1.0|[came, here, for,...|\n",
      "|Bad 1st experienc...|  1.0|[bad, 1st, experi...|\n",
      "|So many great thi...|  4.0|[so, many, great,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rimozione StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora abbiamo ogni recensione rappresentata da una lista di parole, molte di queste parole sono superflue e non portano informazioni utili ai fini della sentiment analysis. Tali parole sono dette **StopWords** ed è buona pratica rimuoverle, possiamo farlo utilizzando la classe **StopWordsRemover** di MLlib.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "stopwords = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "words_df = stopwords.transform(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|                text|stars|               words|            filtered|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|I have been here ...|  4.0|[i, have, been, h...|[twice, nice, lai...|\n",
      "|So far one of the...|  5.0|[so, far, one, of...|[far, one, best, ...|\n",
      "|Came here for hap...|  1.0|[came, here, for,...|[came, happy, hou...|\n",
      "|Bad 1st experienc...|  1.0|[bad, 1st, experi...|[bad, 1st, experi...|\n",
      "|So many great thi...|  4.0|[so, many, great,...|[many, great, thi...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer [Bag of Words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora, utilizzando la colonna 'filtered' come corpus testuale (ogni riga sarà un document), andiamo a generare il **vocabolario dei tokens**; nello specifico, ogni riga di questa nuova colonna che andiamo a generare sarà composta da:\n",
    "\n",
    "* **numero di vocaboli distinti** presi da tutte le righe (sotto la colonna 'words'), dunque facenti parte del vocabolario generato\n",
    "* array degli indici delle **parole (distinte) del vocabolario presenti nella riga** (sotto la colonna 'words')\n",
    "* **numero di volte** in cui si ripresentano le parole del punto precedente\n",
    "\n",
    "Questa tecnica ci consente di convertire una recensione in una lista di numeri (dato che in input a un modello di machine learning possiamo dare numeri e non parole)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol='filtered', outputCol='features')\n",
    "cv_model = cv.fit(words_df)\n",
    "cv_df = cv_model.transform(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |stars|words                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |filtered                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|I have been here twice Very nice and laid back I tried the weekend Southern menu and it was delicious Collard greens maccheese ribs BBQ chicken sandwich The scone with clotted cream was divine The iced teas are very refreshing and I swear I drank a whole container myself both visits \n",
      "The second time I had soup salad and a sandwich The salad had this amazing raspberry strawberry I forgot vinaigrette The sandwich was good but I was kind of disappointed with the soup It was potato and tasted too milky \n",
      "They change the menu often and now have a tea inspired one Cant wait to go back and try it\n",
      "The owners are very nice and I hope they continue to do well|4.0  |[i, have, been, here, twice, very, nice, and, laid, back, i, tried, the, weekend, southern, menu, and, it, was, delicious, collard, greens, maccheese, ribs, bbq, chicken, sandwich, the, scone, with, clotted, cream, was, divine, the, iced, teas, are, very, refreshing, and, i, swear, i, drank, a, whole, container, myself, both, visits, , the, second, time, i, had, soup, salad, and, a, sandwich, the, salad, had, this, amazing, raspberry, strawberry, i, forgot, vinaigrette, the, sandwich, was, good, but, i, was, kind, of, disappointed, with, the, soup, it, was, potato, and, tasted, too, milky, , they, change, the, menu, often, and, now, have, a, tea, inspired, one, cant, wait, to, go, back, and, try, it, the, owners, are, very, nice, and, i, hope, they, continue, to, do, well]|[twice, nice, laid, back, tried, weekend, southern, menu, delicious, collard, greens, maccheese, ribs, bbq, chicken, sandwich, scone, clotted, cream, divine, iced, teas, refreshing, swear, drank, whole, container, visits, , second, time, soup, salad, sandwich, salad, amazing, raspberry, strawberry, forgot, vinaigrette, sandwich, good, kind, disappointed, soup, potato, tasted, milky, , change, menu, often, tea, inspired, one, cant, wait, go, back, try, owners, nice, hope, continue, well]|(101222,[0,2,6,9,10,11,18,19,36,41,42,46,48,58,97,114,118,192,207,228,247,250,269,286,301,308,458,464,476,481,552,592,602,756,783,846,1048,1254,1271,1315,1347,1540,2050,2086,2253,2383,2841,3205,3414,3554,3955,3991,5802,5855,8225,12350,21153],[2.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,2.0,1.0,3.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_df.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In realtà, nel modello **Bag of Words**, un document è rappresentato da un vettore avente lunghezza pari all'ampiezza del vocabolario e ogni suo elemento viene valorizzato con:\n",
    "\n",
    "* **1** laddove la corrispondente parola del vocabolario è presente nel document\n",
    "* **0** laddove questa corrispondenza non sussiste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunque se seguissimo questo apprioccio avremmo, in questo caso, 8021122 di vettori (righe dataset) contenenti ciascuno 101222 elementi (ampiezza dizionario), la maggior parte dei quali pari ovviamente a 0.\n",
    "**Spark**, che tende sempre a ottimizzare l'utilizzo della memoria, utilizza un approccio differente (quello descritto sopra nei 3 punti) che consente di \"salvare\" tantissimo spazio ottenendo lo stesso risultato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora scartiamo pure tutte le colonne intermedie che abbiamo creato tenendo soltanto quelle che ci serviranno per realizzare il modello, features e stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|stars|\n",
      "+--------------------+-----+\n",
      "|(101222,[0,2,6,9,...|  4.0|\n",
      "|(101222,[0,1,2,3,...|  5.0|\n",
      "|(101222,[1,2,4,5,...|  1.0|\n",
      "|(101222,[3,23,30,...|  1.0|\n",
      "|(101222,[0,2,4,6,...|  4.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_df = cv_df.select([\"features\",\"stars\"])\n",
    "cv_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quali sono le recensioni negative ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come abbiamo già detto le recensioni sono accompagnate da una valutazione che va da 1.0 a 5.0 stelle.\n",
    "Etichettiamo come\n",
    "* **positive** le recensioni con una valutazione di almeno 3.5 stelle\n",
    "* **negative** le recensioni con una valutazione inferiore alle 2.5 stelle.\n",
    "* le recensioni con 3 stelle sono tendenzialmente **neutre**, quindi rimuoviamole dal dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "cv_df = cv_df.filter(cv_df.stars != 3)\n",
    "cv_df = cv_df.withColumn('label',when(cv_df['stars'] >= 3.5, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|            features|stars|label|\n",
      "+--------------------+-----+-----+\n",
      "|(101222,[0,2,6,9,...|  4.0|    1|\n",
      "|(101222,[0,1,2,3,...|  5.0|    1|\n",
      "|(101222,[1,2,4,5,...|  1.0|    0|\n",
      "|(101222,[3,23,30,...|  1.0|    0|\n",
      "|(101222,[0,2,4,6,...|  4.0|    1|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Così facendo abbiamo generato un dataset adatto a un modello di apprendimento automatico **supervisionato**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo il metodo *randomSplit* per generare il **train set** e il **test set**\n",
    "* un DataFrame per l'addestramento del modello che conterrà il 70% degli esempi.\n",
    "* un DataFrame per il testing del modello che conterrà il restante 30% degli esempi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = cv_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora possiamo creare il modello, utilizziamo una Regressione Logistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "# in caso di overfitting è possibile utilizzare il parametro 'regParam' per introdurre il meccanismo di regolarizzazione;\n",
    "# infatti regParam è proprio il coefficiente di regolarizzazione\n",
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutiamo il modello addestrato sul DataFrame di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9096118902296976\n",
      "Precision:  [0.8446654611211574, 0.9321533923303835]\n",
      "Recall:  [0.8120653685674548, 0.9453249315766024]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", evaluation.accuracy)\n",
    "print(\"Precision: \",evaluation.precisionByLabel)\n",
    "print(\"Recall: \", evaluation.recallByLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sbilanciamento delle classi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se andiamo a guardare la Recall possiamo notare che c'è una notevole differenza fra il valore relativo alle due classi. Questo vuol dire che il modello performa meglio su una classe rispetto a come performa sul'altra; nel caso in questione, su 100 recensioni negative vengono classificate correttamente 80 mentre su 100 positive 94.\n",
    "In questo caso si parla di **sbilanciamento delle classi**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalmente questo problema è dovuto al fatto che il set di addestramento contiene più esempi appartenenti a una classe rispetto a un'altra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36897\n"
     ]
    }
   ],
   "source": [
    "# Numero esempi di recensioni positive del train set\n",
    "num_pos_revs = train_df.filter(train_df.label == 1).count()\n",
    "print(num_pos_revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13328\n"
     ]
    }
   ],
   "source": [
    "# Numero esempi di recensioni negative del train set\n",
    "num_neg_revs = train_df.filter(train_df.label == 0).count()\n",
    "print(num_neg_revs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunque il train set è fortemente sbilanciato a favore degli esempi appartenenti alla classe positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per rimediare a questo inconveniente la soluzione ideale sarebbe arricchire il dataset con esempi relativi alla classe meno presente; laddove non fosse possibile possiamo **penalizzare la classe verso cui è sbilanciato il dataset assegnandogli un peso**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una giusta scelta potrebbe essere quella di scegliere tale peso sulla base del rapporto fra le percentuali di esempi del dataset relativi alle due classi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "pos_weight = float(\"{:.2f}\".format(num_pos_revs/(num_pos_revs + num_neg_revs)))\n",
    "print(pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27\n"
     ]
    }
   ],
   "source": [
    "neg_weight = 1 - pos_weight\n",
    "print(neg_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto costruisco una nuova colonna nel train set per inserire il peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+------+\n",
      "|            features|stars|label|weight|\n",
      "+--------------------+-----+-----+------+\n",
      "|(101222,[0,1,2,3,...|  5.0|    1|  0.27|\n",
      "|(101222,[0,1,2,3,...|  4.0|    1|  0.27|\n",
      "|(101222,[0,1,2,3,...|  4.0|    1|  0.27|\n",
      "|(101222,[0,1,2,3,...|  5.0|    1|  0.27|\n",
      "|(101222,[0,1,2,3,...|  4.0|    1|  0.27|\n",
      "|(101222,[0,1,2,3,...|  1.0|    0|  0.73|\n",
      "|(101222,[0,1,2,3,...|  4.0|    1|  0.27|\n",
      "|(101222,[0,1,2,3,...|  5.0|    1|  0.27|\n",
      "|(101222,[0,1,2,3,...|  4.0|    1|  0.27|\n",
      "|(101222,[0,1,2,3,...|  5.0|    1|  0.27|\n",
      "+--------------------+-----+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.withColumn('weight',when(cv_df['stars'] >= 3.5, neg_weight).otherwise(pos_weight))\n",
    "train_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto rigeneriamo il modello tenendo conto anche della colonna dei pesi tramite il parametro **weightCol**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", weightCol = \"weight\")\n",
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutiamo il modello addestrato sul DataFrame di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9035549550389042\n",
      "Precision:  [0.8544474393530997, 0.9192328969205237]\n",
      "Recall:  [0.771557719054242, 0.9518808478136338]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", evaluation.accuracy)\n",
    "print(\"Precision: \",evaluation.precisionByLabel)\n",
    "print(\"Recall: \", evaluation.recallByLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andando ad osservare le metriche non possiamo affermare di aver migliorato il modello, nè dal punto di vista dell'accuratezza nè da quello dello sblianciamento delle classi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunque meglio provare con un altro modello (vedi più avanti)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creiamo un modello con tutti i dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finora abbiamo utilizzato solo l'1% dei dati a nostra disposizione per generare il nostro modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volendo addestrare il modello utilizzando il **dataset per intero** con tutti le sue **6.685.900 recensioni** verrebbero richieste molte risorse di calcolo e, di conseguenza, tempo. Si dovrebbe utilizzare almeno una macchina EC2 di tipo t3a.large (costo ~7 centesimi l'ora) o meglio ancora un cluster con EMR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo a generare ora un nuovo modello utilizzando, anzichè il Bag of Words, il **TF-IDF** (Term Frequency - Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = yelp_df.select('text','stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|stars|\n",
      "+--------------------+-----+\n",
      "|As someone who ha...|  2.0|\n",
      "|I am actually hor...|  1.0|\n",
      "|I love Deagan's. ...|  5.0|\n",
      "|Dismal, lukewarm,...|  1.0|\n",
      "|Oh happy day, fin...|  4.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cominciamo creando un modello utilizzando soltanto il 1% del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreviews_df = reviews_df.sample(fraction=0.01, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing del testo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rimozione della punteggiatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|stars|\n",
      "+--------------------+-----+\n",
      "|I have been here ...|  4.0|\n",
      "|So far one of the...|  5.0|\n",
      "|Came here for hap...|  1.0|\n",
      "|Bad 1st experienc...|  1.0|\n",
      "|So many great thi...|  4.0|\n",
      "|Great food  Get t...|  4.0|\n",
      "|Super personable ...|  5.0|\n",
      "|Clean nice and fr...|  4.0|\n",
      "|I love their food...|  4.0|\n",
      "|This hot and read...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@udf()\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "subreviews_df = subreviews_df.withColumn('text', remove_punct(col('text')))\n",
    "subreviews_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "words_df = tokenizer.transform(subreviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|                text|stars|               words|\n",
      "+--------------------+-----+--------------------+\n",
      "|I have been here ...|  4.0|[i, have, been, h...|\n",
      "|So far one of the...|  5.0|[so, far, one, of...|\n",
      "|Came here for hap...|  1.0|[came, here, for,...|\n",
      "|Bad 1st experienc...|  1.0|[bad, 1st, experi...|\n",
      "|So many great thi...|  4.0|[so, many, great,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rimozione StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "words_df = stopwords.transform(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|                text|stars|               words|            filtered|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|I have been here ...|  4.0|[i, have, been, h...|[twice, nice, lai...|\n",
      "|So far one of the...|  5.0|[so, far, one, of...|[far, one, best, ...|\n",
      "|Came here for hap...|  1.0|[came, here, for,...|[came, happy, hou...|\n",
      "|Bad 1st experienc...|  1.0|[bad, 1st, experi...|[bad, 1st, experi...|\n",
      "|So many great thi...|  4.0|[so, many, great,...|[many, great, thi...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa volta, piuttosto che usare un semplice modello Bag of Words per la rappresentazione delle parole, usiamo un modello più sofisticato, il TF-IDF (Term Frequency - Inverse Document Frequency) che assegna un peso maggiore alle parole più rare e penalizza quelle più comuni.\n",
    "Nello specifico:\n",
    "\n",
    "* **Term Frequency**:  è il numero di volte in cui un termine appare in un documento (ovvero una riga del dataset)\n",
    "* **Inverse Document Frequency**: è il numero di documenti (ovvero righe del dataset) che contiene un determinato termine\n",
    "\n",
    "Anche in questo caso, come succedeva utilzzando le Bags of Words, **Spark** utilizza un approccio che consente di \"salvare\" spazio ottenendo lo stesso risultato (viene utilizzata una funzione di hash)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "hashing_tf = HashingTF(inputCol='filtered', outputCol='raw_features')\n",
    "words_df = hashing_tf.transform(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idf_model = idf.fit(words_df)\n",
    "words_df = idf_model.transform(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |stars|words                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |filtered                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |raw_features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|I have been here twice Very nice and laid back I tried the weekend Southern menu and it was delicious Collard greens maccheese ribs BBQ chicken sandwich The scone with clotted cream was divine The iced teas are very refreshing and I swear I drank a whole container myself both visits \n",
      "The second time I had soup salad and a sandwich The salad had this amazing raspberry strawberry I forgot vinaigrette The sandwich was good but I was kind of disappointed with the soup It was potato and tasted too milky \n",
      "They change the menu often and now have a tea inspired one Cant wait to go back and try it\n",
      "The owners are very nice and I hope they continue to do well|4.0  |[i, have, been, here, twice, very, nice, and, laid, back, i, tried, the, weekend, southern, menu, and, it, was, delicious, collard, greens, maccheese, ribs, bbq, chicken, sandwich, the, scone, with, clotted, cream, was, divine, the, iced, teas, are, very, refreshing, and, i, swear, i, drank, a, whole, container, myself, both, visits, , the, second, time, i, had, soup, salad, and, a, sandwich, the, salad, had, this, amazing, raspberry, strawberry, i, forgot, vinaigrette, the, sandwich, was, good, but, i, was, kind, of, disappointed, with, the, soup, it, was, potato, and, tasted, too, milky, , they, change, the, menu, often, and, now, have, a, tea, inspired, one, cant, wait, to, go, back, and, try, it, the, owners, are, very, nice, and, i, hope, they, continue, to, do, well]|[twice, nice, laid, back, tried, weekend, southern, menu, delicious, collard, greens, maccheese, ribs, bbq, chicken, sandwich, scone, clotted, cream, divine, iced, teas, refreshing, swear, drank, whole, container, visits, , second, time, soup, salad, sandwich, salad, amazing, raspberry, strawberry, forgot, vinaigrette, sandwich, good, kind, disappointed, soup, potato, tasted, milky, , change, menu, often, tea, inspired, one, cant, wait, go, back, try, owners, nice, hope, continue, well]|(262144,[3856,4333,8706,12575,15705,21823,22346,32727,36797,39239,39530,52471,57504,58534,79132,79160,80112,80707,82761,93838,96611,104896,113432,121517,128160,132270,138837,147398,148675,150069,151571,157192,158060,158102,162058,165808,167290,186925,188819,190119,193142,196752,197865,199468,199567,201845,208694,208742,213605,223059,225612,235351,240323,240544,243658,249180,250712],[1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,3.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0])|(262144,[3856,4333,8706,12575,15705,21823,22346,32727,36797,39239,39530,52471,57504,58534,79132,79160,80112,80707,82761,93838,96611,104896,113432,121517,128160,132270,138837,147398,148675,150069,151571,157192,158060,158102,162058,165808,167290,186925,188819,190119,193142,196752,197865,199468,199567,201845,208694,208742,213605,223059,225612,235351,240323,240544,243658,249180,250712],[4.980132428702442,5.584756973106481,3.3827450546439453,9.345957088800043,5.944759707137888,1.4852210367687844,3.8688016019777605,3.5749611025569683,3.7869251694591854,4.694721535968705,5.8757668356509365,3.635530071425174,7.3406235192739295,6.127081263931843,3.108749158460611,3.4251449527186284,7.62830559172571,3.3652646386739726,6.037061278701741,2.7335321031079443,3.841206441643817,8.519278515615575,1.13133724899956,1.3764017085598217,4.072957530236296,2.8409794784749245,4.04692569151835,7.091998016126177,1.5711613479456399,2.4483964562279756,4.768509793072452,4.118675495368758,6.2104628728708935,3.159160748162092,7.7365191763659436,4.515360245483174,10.428770117460498,1.9344871232298593,6.555668789460861,4.469669847234866,4.175473093761892,5.130659916160281,2.4626408831235076,2.180574019480408,5.649960166917244,4.622369147997477,6.315133495434782,2.235844226263531,2.133873346251383,3.9203779426410796,5.336029868390526,4.969301997928072,6.401518109633603,6.512743744743828,2.60543772919382,1.0139405906065144,5.111850584202784])|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|stars|               words|            filtered|        raw_features|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|I have been here ...|  4.0|[i, have, been, h...|[twice, nice, lai...|(262144,[3856,433...|(262144,[3856,433...|\n",
      "|So far one of the...|  5.0|[so, far, one, of...|[far, one, best, ...|(262144,[12057,13...|(262144,[12057,13...|\n",
      "|Came here for hap...|  1.0|[came, here, for,...|[came, happy, hou...|(262144,[1094,343...|(262144,[1094,343...|\n",
      "|Bad 1st experienc...|  1.0|[bad, 1st, experi...|[bad, 1st, experi...|(262144,[25491,32...|(262144,[25491,32...|\n",
      "|So many great thi...|  4.0|[so, many, great,...|[many, great, thi...|(262144,[329,3837...|(262144,[329,3837...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto, come già fatto prima, rimuoviamo le recensioni con 3 stelle e valutiamo positivamente quelle con un numero maggiore di stelle e negativamente tutte le altre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = words_df.filter(cv_df.stars != 3)\n",
    "words_df = words_df.withColumn('label',when(cv_df['stars'] >= 3.5, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|                text|stars|               words|            filtered|        raw_features|            features|label|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|I have been here ...|  4.0|[i, have, been, h...|[twice, nice, lai...|(262144,[3856,433...|(262144,[3856,433...|    1|\n",
      "|So far one of the...|  5.0|[so, far, one, of...|[far, one, best, ...|(262144,[12057,13...|(262144,[12057,13...|    1|\n",
      "|Came here for hap...|  1.0|[came, here, for,...|[came, happy, hou...|(262144,[1094,343...|(262144,[1094,343...|    0|\n",
      "|Bad 1st experienc...|  1.0|[bad, 1st, experi...|[bad, 1st, experi...|(262144,[25491,32...|(262144,[25491,32...|    0|\n",
      "|So many great thi...|  4.0|[so, many, great,...|[many, great, thi...|(262144,[329,3837...|(262144,[329,3837...|    1|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train set e Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiamo il dataframe in set di addestramento e di test, avendo moltissimi esempi possiamo anche ridurre la dimensione del set di test al 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = words_df.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generazione dle modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddvvWMl3Iwvb"
   },
   "source": [
    "Creiamo il modello e addestriamolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmkEye3-Iwvb"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d0YTlVKwIwvd"
   },
   "source": [
    "Valutiamolo sul set di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUko_MfkIwvd",
    "outputId": "f164112d-ab0f-4a45-ace1-65f5053c3344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090035684875103\n",
      "[0.8404255319148937, 0.9344879518072289]\n",
      "[0.8266068759342302, 0.9403296078802803]\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(test_df)\n",
    "print(evaluation.accuracy)\n",
    "print(evaluation.precisionByLabel)\n",
    "print(evaluation.recallByLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello sembra essere un po' più performante rispetto al Bag of Words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testo il modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8L5SFlksIwvh"
   },
   "outputs": [],
   "source": [
    "reviews = [\n",
    "        (\"World's Largest Entertainment McDonald's\",\"Lazy staff who do not want to serve u would rather stand in corners in groups talking stood at counter 10 minutes with all staff refusing eye contact as fear of having to serve u supervisor went over and shouted at staff they all stood there shrugging shoulders not wanting t serve u then when orders were ready staff came with trays dragging feet and rolling eyes then it was cold horrible won’t return !!\"),\n",
    "        (\"Disnayland Paris\",\"Went here 2x with my husband and found it more magical the 2nd time. Still the happiest place on earth on my list. It gets better and better.\"),\n",
    "        (\"58 Tour Eiffel Restaurant\",\"What an experience! what a VIEW!. what a meal!!... Delicious, fine dining. excellent0 excellent service and food. A memory of a lifetime\"),\n",
    "        (\"Ristorante Cracco\",\"If you want to start your trip in Milan with good mood, for sure you have to avoid this restaurant - the worst pizza we had and the smallest portion of pasta! And incompatible price for that everything! Even, I am really angry, because this is not my first visit in Italy and not first pizza and I feel myself like ....!!!!\"),\n",
    "        (\"Happy Wok\",\"Stay away as far as you can, unless you like goopy tables and mass produced food that appeared to be sitting out for too long. It wasn’t a nice experience and we will not attempt to go back under any circumstance\"),\n",
    "        (\"Pepe in grani\",\"45 minutes driving from Naples center. Worth every moment on the way. The best and the most unique pizza I ever tasted. Very nice place, every centimeter was well though and planned before implemented. Nice terrace on top for those like the view. Very welcoming crew, great and fast service. Recommend to order the tasting option for those coming in parties of four. \")\n",
    "    ]\n",
    "\n",
    "test_df = spark.createDataFrame(reviews, [\"location\",\"text\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            location|                text|\n",
      "+--------------------+--------------------+\n",
      "|World's Largest E...|Lazy staff who do...|\n",
      "|    Disnayland Paris|Went here 2x with...|\n",
      "|58 Tour Eiffel Re...|What an experienc...|\n",
      "|   Ristorante Cracco|If you want to st...|\n",
      "|           Happy Wok|Stay away as far ...|\n",
      "|       Pepe in grani|45 minutes drivin...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROIlF3jEIwvj"
   },
   "outputs": [],
   "source": [
    "test_df = test_df.withColumn(\"text\", remove_punct(col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            location|                text|\n",
      "+--------------------+--------------------+\n",
      "|World's Largest E...|Lazy staff who do...|\n",
      "|    Disnayland Paris|Went here 2x with...|\n",
      "|58 Tour Eiffel Re...|What an experienc...|\n",
      "|   Ristorante Cracco|If you want to st...|\n",
      "|           Happy Wok|Stay away as far ...|\n",
      "|       Pepe in grani|45 minutes drivin...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYbjh14DIwvm"
   },
   "outputs": [],
   "source": [
    "test_df = tokenizer.transform(test_df)\n",
    "test_df = stopwords.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|            location|                text|               words|            filtered|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|World's Largest E...|Lazy staff who do...|[lazy, staff, who...|[lazy, staff, wan...|\n",
      "|    Disnayland Paris|Went here 2x with...|[went, here, 2x, ...|[went, 2x, husban...|\n",
      "|58 Tour Eiffel Re...|What an experienc...|[what, an, experi...|[experience, view...|\n",
      "|   Ristorante Cracco|If you want to st...|[if, you, want, t...|[want, start, tri...|\n",
      "|           Happy Wok|Stay away as far ...|[stay, away, as, ...|[stay, away, far,...|\n",
      "|       Pepe in grani|45 minutes drivin...|[45, minutes, dri...|[45, minutes, dri...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgHh2YU7Iwvo"
   },
   "outputs": [],
   "source": [
    "test_df = hashing_tf.transform(test_df)\n",
    "test_df = idf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|            location|                text|               words|            filtered|        raw_features|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|World's Largest E...|Lazy staff who do...|[lazy, staff, who...|[lazy, staff, wan...|(262144,[3524,844...|(262144,[3524,844...|\n",
      "|    Disnayland Paris|Went here 2x with...|[went, here, 2x, ...|[went, 2x, husban...|(262144,[14376,31...|(262144,[14376,31...|\n",
      "|58 Tour Eiffel Re...|What an experienc...|[what, an, experi...|[experience, view...|(262144,[10077,17...|(262144,[10077,17...|\n",
      "|   Ristorante Cracco|If you want to st...|[if, you, want, t...|[want, start, tri...|(262144,[16004,28...|(262144,[16004,28...|\n",
      "|           Happy Wok|Stay away as far ...|[stay, away, as, ...|[stay, away, far,...|(262144,[9129,223...|(262144,[9129,223...|\n",
      "|       Pepe in grani|45 minutes drivin...|[45, minutes, dri...|[45, minutes, dri...|(262144,[8195,870...|(262144,[8195,870...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7D8xO7WIwvq"
   },
   "outputs": [],
   "source": [
    "pred_df = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|location                                |text                                                                                                                                                                                                                                                                                                                                                                                                                |prediction|\n",
      "+----------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|World's Largest Entertainment McDonald's|Lazy staff who do not want to serve u would rather stand in corners in groups talking stood at counter 10 minutes with all staff refusing eye contact as fear of having to serve u supervisor went over and shouted at staff they all stood there shrugging shoulders not wanting t serve u then when orders were ready staff came with trays dragging feet and rolling eyes then it was cold horrible won’t return |0.0       |\n",
      "|Disnayland Paris                        |Went here 2x with my husband and found it more magical the 2nd time Still the happiest place on earth on my list It gets better and better                                                                                                                                                                                                                                                                          |1.0       |\n",
      "|58 Tour Eiffel Restaurant               |What an experience what a VIEW what a meal Delicious fine dining excellent0 excellent service and food A memory of a lifetime                                                                                                                                                                                                                                                                                       |1.0       |\n",
      "|Ristorante Cracco                       |If you want to start your trip in Milan with good mood for sure you have to avoid this restaurant  the worst pizza we had and the smallest portion of pasta And incompatible price for that everything Even I am really angry because this is not my first visit in Italy and not first pizza and I feel myself like                                                                                                |0.0       |\n",
      "|Happy Wok                               |Stay away as far as you can unless you like goopy tables and mass produced food that appeared to be sitting out for too long It wasn’t a nice experience and we will not attempt to go back under any circumstance                                                                                                                                                                                                  |0.0       |\n",
      "|Pepe in grani                           |45 minutes driving from Naples center Worth every moment on the way The best and the most unique pizza I ever tasted Very nice place every centimeter was well though and planned before implemented Nice terrace on top for those like the view Very welcoming crew great and fast service Recommend to order the tasting option for those coming in parties of four                                               |0.0       |\n",
      "+----------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df.select(['location','text','prediction']).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
