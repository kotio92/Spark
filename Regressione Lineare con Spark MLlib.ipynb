{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressione Lineare con Spark MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo notebook vedremo come eseguire una semplice regressione lineare con il modulo MLlib di Spark. Il modello che andremo a creare avrà lo scopo di stimare il valore di un'abitazione utilizzando un set di proprietà:\n",
    "\n",
    "* **CRIM** Tasso di criminalità per capita\n",
    "* **ZN** Percentuale di terreni residenziali suddivisi in zone per lotti superiori a 25.000 sq.ft.\n",
    "* **INDUS** Percentuale di ettari di attività non al dettaglio per città.\n",
    "* **CHAS** Variabile dummy che indica la prossimità al fiume Charles.\n",
    "* **NOX** Concentrazione di ossido d'azoto (parti per 10 milioni).\n",
    "* **RM** Numero medio di stanze per abitazione\n",
    "* **AGE** Percentuale di abitazione occupate costruite dopo il 1940\n",
    "* **DIS** Media pesata delle distanze da 5 centri lavorativi di Boston.\n",
    "* **RAD** Indice di accessibilità ad autostrade\n",
    "* **TAX** Aliquota dell'imposta sulla proprietà a valore pieno in 10.000 USD.\n",
    "* **PRATIO**** Rapporto studente-insegnante per città.\n",
    "* **BLACK** 1000(Bk - 0.63)^2 dove Bk è la percentuale di abitanti di colore per città\n",
    "* **LSTAT** Percentuale della popolazione povera\n",
    "* **MEDV** Mediana del valore di abitazioni occupate in 1.000 USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importazione delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark.sql.functions\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializzazione di Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basic').getOrCreate()\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importazione del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset che utilizzeremo è il **Boston Housing Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = spark.read.csv('HousingData.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM| AGE|   DIS|RAD|TAX|PTRATIO|     B|LSTAT|MEDV|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|  18| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
      "|0.02731|   0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|0.02729|   0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n",
      "|0.03237|   0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|0.06905|   0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9|   NA|36.2|\n",
      "|0.02985|   0| 2.18|   0|0.458| 6.43|58.7|6.0622|  3|222|   18.7|394.12| 5.21|28.7|\n",
      "|0.08829|12.5| 7.87|  NA|0.524|6.012|66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|\n",
      "|0.14455|12.5| 7.87|   0|0.524|6.172|96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|\n",
      "|0.21124|12.5| 7.87|   0|0.524|5.631| 100|6.0821|  5|311|   15.2|386.63|29.93|16.5|\n",
      "|0.17004|12.5| 7.87|  NA|0.524|6.004|85.9|6.5921|  5|311|   15.2|386.71| 17.1|18.9|\n",
      "|0.22489|12.5| 7.87|   0|0.524|6.377|94.3|6.3467|  5|311|   15.2|392.52|20.45|15.0|\n",
      "|0.11747|12.5| 7.87|   0|0.524|6.009|82.9|6.2267|  5|311|   15.2| 396.9|13.27|18.9|\n",
      "|0.09378|12.5| 7.87|   0|0.524|5.889|  39|5.4509|  5|311|   15.2| 390.5|15.71|21.7|\n",
      "|0.62976|   0| 8.14|   0|0.538|5.949|61.8|4.7075|  4|307|   21.0| 396.9| 8.26|20.4|\n",
      "|0.63796|   0| 8.14|  NA|0.538|6.096|84.5|4.4619|  4|307|   21.0|380.02|10.26|18.2|\n",
      "|0.62739|   0| 8.14|   0|0.538|5.834|56.5|4.4986|  4|307|   21.0|395.62| 8.47|19.9|\n",
      "|1.05393|   0| 8.14|   0|0.538|5.935|29.3|4.4986|  4|307|   21.0|386.85| 6.58|23.1|\n",
      "| 0.7842|   0| 8.14|   0|0.538| 5.99|81.7|4.2579|  4|307|   21.0|386.75|14.67|17.5|\n",
      "|0.80271|   0| 8.14|   0|0.538|5.456|36.6|3.7965|  4|307|   21.0|288.99|11.69|20.2|\n",
      "| 0.7258|   0| 8.14|   0|0.538|5.727|69.5|3.7965|  4|307|   21.0|390.95|11.28|18.2|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRIM: string (nullable = true)\n",
      " |-- ZN: string (nullable = true)\n",
      " |-- INDUS: string (nullable = true)\n",
      " |-- CHAS: string (nullable = true)\n",
      " |-- NOX: double (nullable = true)\n",
      " |-- RM: double (nullable = true)\n",
      " |-- AGE: string (nullable = true)\n",
      " |-- DIS: double (nullable = true)\n",
      " |-- RAD: integer (nullable = true)\n",
      " |-- TAX: integer (nullable = true)\n",
      " |-- PTRATIO: double (nullable = true)\n",
      " |-- B: double (nullable = true)\n",
      " |-- LSTAT: string (nullable = true)\n",
      " |-- MEDV: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' necessario modificare alcuni tipi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('CRIM',FloatType(), True),\n",
    "               StructField('ZN',FloatType(), True),\n",
    "               StructField('INDUS',FloatType(), True),\n",
    "               StructField('CHAS',IntegerType(), True),\n",
    "               StructField('NOX',FloatType(), True),\n",
    "               StructField('RM',FloatType(), True),\n",
    "               StructField('AGE',FloatType(), True),\n",
    "               StructField('DIS',FloatType(), True),\n",
    "               StructField('RAD',IntegerType(), True),\n",
    "               StructField('TAX',IntegerType(), True),\n",
    "               StructField('PTRATIO',FloatType(), True),\n",
    "               StructField('B',FloatType(), True),\n",
    "               StructField('LSTAT',FloatType(), True),\n",
    "               StructField('MEDV',FloatType(), True)]\n",
    "\n",
    "schema = StructType(fields = data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = spark.read.csv('HousingData.csv', header=True, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM|  AGE|   DIS|RAD|TAX|PTRATIO|     B|LSTAT|MEDV|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575| 65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421| 78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185| 61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998| 45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147| 54.2|6.0622|  3|222|   18.7| 396.9| null|36.2|\n",
      "|0.02985| 0.0| 2.18|   0|0.458| 6.43| 58.7|6.0622|  3|222|   18.7|394.12| 5.21|28.7|\n",
      "|0.08829|12.5| 7.87|null|0.524|6.012| 66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|\n",
      "|0.14455|12.5| 7.87|   0|0.524|6.172| 96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|\n",
      "|0.21124|12.5| 7.87|   0|0.524|5.631|100.0|6.0821|  5|311|   15.2|386.63|29.93|16.5|\n",
      "|0.17004|12.5| 7.87|null|0.524|6.004| 85.9|6.5921|  5|311|   15.2|386.71| 17.1|18.9|\n",
      "|0.22489|12.5| 7.87|   0|0.524|6.377| 94.3|6.3467|  5|311|   15.2|392.52|20.45|15.0|\n",
      "|0.11747|12.5| 7.87|   0|0.524|6.009| 82.9|6.2267|  5|311|   15.2| 396.9|13.27|18.9|\n",
      "|0.09378|12.5| 7.87|   0|0.524|5.889| 39.0|5.4509|  5|311|   15.2| 390.5|15.71|21.7|\n",
      "|0.62976| 0.0| 8.14|   0|0.538|5.949| 61.8|4.7075|  4|307|   21.0| 396.9| 8.26|20.4|\n",
      "|0.63796| 0.0| 8.14|null|0.538|6.096| 84.5|4.4619|  4|307|   21.0|380.02|10.26|18.2|\n",
      "|0.62739| 0.0| 8.14|   0|0.538|5.834| 56.5|4.4986|  4|307|   21.0|395.62| 8.47|19.9|\n",
      "|1.05393| 0.0| 8.14|   0|0.538|5.935| 29.3|4.4986|  4|307|   21.0|386.85| 6.58|23.1|\n",
      "| 0.7842| 0.0| 8.14|   0|0.538| 5.99| 81.7|4.2579|  4|307|   21.0|386.75|14.67|17.5|\n",
      "|0.80271| 0.0| 8.14|   0|0.538|5.456| 36.6|3.7965|  4|307|   21.0|288.99|11.69|20.2|\n",
      "| 0.7258| 0.0| 8.14|   0|0.538|5.727| 69.5|3.7965|  4|307|   21.0|390.95|11.28|18.2|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valori nulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Innanziutto verifichiamo la presenza di valori nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.filter(housing_df[\"CRIM\"].isNull() | \\\n",
    "                  housing_df[\"ZN\"].isNull() | \\\n",
    "                  housing_df[\"INDUS\"].isNull() | \\\n",
    "                  housing_df[\"CHAS\"].isNull() | \\\n",
    "                  housing_df[\"NOX\"].isNull() | \\\n",
    "                  housing_df[\"RM\"].isNull() | \\\n",
    "                  housing_df[\"AGE\"].isNull() | \\\n",
    "                  housing_df[\"DIS\"].isNull() | \\\n",
    "                  housing_df[\"RAD\"].isNull() | \\\n",
    "                  housing_df[\"TAX\"].isNull() | \\\n",
    "                  housing_df[\"PTRATIO\"].isNull() | \\\n",
    "                  housing_df[\"B\"].isNull() | \\\n",
    "                  housing_df[\"LSTAT\"].isNull() | \\\n",
    "                  housing_df[\"MEDV\"].isNull() \\\n",
    "                 ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "112 righe su 506 presentano almeno un valore nullo. Per ragioni di semplicità andiamo a rimuovere tali righe (in teoria sarebbe meglio fare risolvere la cosa diversamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = housing_df.filter(housing_df[\"CRIM\"].isNotNull() & \\\n",
    "                              housing_df[\"ZN\"].isNotNull() & \\\n",
    "                              housing_df[\"INDUS\"].isNotNull() & \\\n",
    "                              housing_df[\"CHAS\"].isNotNull() & \\\n",
    "                              housing_df[\"NOX\"].isNotNull() & \\\n",
    "                              housing_df[\"RM\"].isNotNull() & \\\n",
    "                              housing_df[\"AGE\"].isNotNull() & \\\n",
    "                              housing_df[\"DIS\"].isNotNull() & \\\n",
    "                              housing_df[\"RAD\"].isNotNull() & \\\n",
    "                              housing_df[\"TAX\"].isNotNull() & \\\n",
    "                              housing_df[\"PTRATIO\"].isNotNull() & \\\n",
    "                              housing_df[\"B\"].isNotNull() & \\\n",
    "                              housing_df[\"LSTAT\"].isNotNull() & \\\n",
    "                              housing_df[\"MEDV\"].isNotNull() \\\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM|  AGE|   DIS|RAD|TAX|PTRATIO|     B|LSTAT|MEDV|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575| 65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421| 78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185| 61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998| 45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|0.02985| 0.0| 2.18|   0|0.458| 6.43| 58.7|6.0622|  3|222|   18.7|394.12| 5.21|28.7|\n",
      "|0.14455|12.5| 7.87|   0|0.524|6.172| 96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|\n",
      "|0.21124|12.5| 7.87|   0|0.524|5.631|100.0|6.0821|  5|311|   15.2|386.63|29.93|16.5|\n",
      "|0.22489|12.5| 7.87|   0|0.524|6.377| 94.3|6.3467|  5|311|   15.2|392.52|20.45|15.0|\n",
      "|0.11747|12.5| 7.87|   0|0.524|6.009| 82.9|6.2267|  5|311|   15.2| 396.9|13.27|18.9|\n",
      "|0.09378|12.5| 7.87|   0|0.524|5.889| 39.0|5.4509|  5|311|   15.2| 390.5|15.71|21.7|\n",
      "|0.62976| 0.0| 8.14|   0|0.538|5.949| 61.8|4.7075|  4|307|   21.0| 396.9| 8.26|20.4|\n",
      "|0.62739| 0.0| 8.14|   0|0.538|5.834| 56.5|4.4986|  4|307|   21.0|395.62| 8.47|19.9|\n",
      "|1.05393| 0.0| 8.14|   0|0.538|5.935| 29.3|4.4986|  4|307|   21.0|386.85| 6.58|23.1|\n",
      "| 0.7842| 0.0| 8.14|   0|0.538| 5.99| 81.7|4.2579|  4|307|   21.0|386.75|14.67|17.5|\n",
      "|0.80271| 0.0| 8.14|   0|0.538|5.456| 36.6|3.7965|  4|307|   21.0|288.99|11.69|20.2|\n",
      "| 0.7258| 0.0| 8.14|   0|0.538|5.727| 69.5|3.7965|  4|307|   21.0|390.95|11.28|18.2|\n",
      "|1.25179| 0.0| 8.14|   0|0.538| 5.57| 98.1|3.7979|  4|307|   21.0|376.57|21.02|13.6|\n",
      "|0.85204| 0.0| 8.14|   0|0.538|5.965| 89.2|4.0123|  4|307|   21.0|392.53|13.83|19.6|\n",
      "|1.23247| 0.0| 8.14|   0|0.538|6.142| 91.7|3.9769|  4|307|   21.0| 396.9|18.72|15.2|\n",
      "|0.98843| 0.0| 8.14|   0|0.538|5.813|100.0|4.0952|  4|307|   21.0|394.54|19.88|14.5|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero una lista con i nomi delle colonne che saranno le features del nostro modello, cioè tutte le colonne meno il target (MEDV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = housing_df.columns[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe MLlib richiede che le features si trovino tutte all'interno di un unico vettore su di una colonna, possiamo creare questa rappresentazione utilizzando la classe VectorAssemlber di MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=columns, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = assembler.transform(housing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|CRIM   |ZN  |INDUS|CHAS|NOX  |RM   |AGE |DIS   |RAD|TAX|PTRATIO|B     |LSTAT|MEDV|features                                                                                                                                                                                   |\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0.00632|18.0|2.31 |0   |0.538|6.575|65.2|4.09  |1  |296|15.3   |396.9 |4.98 |24.0|[0.006320000160485506,18.0,2.309999942779541,0.0,0.5379999876022339,6.574999809265137,65.19999694824219,4.090000152587891,1.0,296.0,15.300000190734863,396.8999938964844,4.980000019073486]|\n",
      "|0.02731|0.0 |7.07 |0   |0.469|6.421|78.9|4.9671|2  |242|17.8   |396.9 |9.14 |21.6|[0.027310000732541084,0.0,7.070000171661377,0.0,0.4690000116825104,6.421000003814697,78.9000015258789,4.967100143432617,2.0,242.0,17.799999237060547,396.8999938964844,9.140000343322754]  |\n",
      "|0.02729|0.0 |7.07 |0   |0.469|7.185|61.1|4.9671|2  |242|17.8   |392.83|4.03 |34.7|[0.027289999648928642,0.0,7.070000171661377,0.0,0.4690000116825104,7.184999942779541,61.099998474121094,4.967100143432617,2.0,242.0,17.799999237060547,392.8299865722656,4.03000020980835] |\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show(n=3,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' buona norma portare le features in un range di valori comuni, questo processo può velocizzare anche di molto la fase di addestramento. Facciamolo utilizzando la **normalizzazione** che si esegue sottraendo il valore minimo e poi dividendo per la differenza tra valore massimo e valore minimo. Possiamo eseguire la normalizzazione con MLlib usando la classe **MinMaxScaler**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "scaler_model = scaler.fit(data_df)\n",
    "data_df = scaler_model.transform(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+--------------------+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM| AGE|   DIS|RAD|TAX|PTRATIO|     B|LSTAT|MEDV|            features|     scaled_features|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+--------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|[0.00632000016048...|[0.0,0.18,0.06781...|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|[0.02731000073254...|[2.35922555448959...|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|[0.02728999964892...|[2.35697748082166...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set e Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prossimo passo, dividere il DataFrame con le features preprocessate in due DataFrame, uno per l'**addestramento** e uno per il **testing** del modello, possiamo farlo utilizzando il metodo **randomSplit** all'interno della quale dobbiamo passare una lista con la percentuale di osservazioni da assegnare ad ognuno dei DataFrame.\n",
    "Nel nostro caso assegnamo il 70% degli esempi al set di addestramento e il 30% al set di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 esempi nel train set\n",
      "113 esempi nel test set\n"
     ]
    }
   ],
   "source": [
    "print(\"%d esempi nel train set\" % train_df.count())\n",
    "print(\"%d esempi nel test set\" % test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+--------------------+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM| AGE|   DIS|RAD|TAX|PTRATIO|     B|LSTAT|MEDV|            features|     scaled_features|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+--------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|[0.00632000016048...|[0.0,0.18,0.06781...|\n",
      "|0.01301|35.0| 1.52|   0|0.442|7.241|49.3|7.0379|  1|284|   15.5|394.74| 5.49|32.7|[0.01300999987870...|[7.51939869680761...|\n",
      "|0.01311|90.0| 1.22|   0|0.403|7.249|21.9|8.6966|  5|226|   17.9|395.93| 4.81|35.4|[0.01310999970883...|[7.63179609949933...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generazione del modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ottimo ! Possiamo creare il modello di Regressione Lineare, usiamo la classe **LinearRegression**, all'interno del costruttore dovremo passare due parametri:\n",
    "\n",
    "* **featuresCol**: il nome della colonna con le features\n",
    "* **labelCol**: il nome della colonna con il target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"scaled_features\", labelCol=\"MEDV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avviamo l'addestramento con il metodo fit, passando al suo interno il set di addetramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo creato il nostro modello ! Ora verifichiamone la qualità testandolo su dati che non ha visto durante l'addestramento, possiamo farlo usando il test set e il metodo evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Il metodo evaluate calcolerà diverse metriche che ci possono aiutare a comprendere la qualità del modello, vediamone alcune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione del modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE - Mean Absolute Error (Errore medio assoluto)\n",
    "\n",
    "L'errore medio assoluto consiste nella media della somma del valore assoluto degli errori.\n",
    "\n",
    "$$ MAE = \\frac{\\sum_{i=1}^n |y_i-\\hat{y}_i|}{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE - Mean Squared Error (Errore quadratico assoluto)\n",
    "\n",
    "L'errore quadratico medio consiste nella media della somma degli errori al quadrato.\n",
    "\n",
    "$$ MSE =  \\frac{\\sum_{i=1}^n (y_i-\\hat{y}_i)^2}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE - Root Mean Squared Error (Radice dell'errore quadratico medio)\n",
    "\n",
    "Il RMSE è la radice dell'errore quadratico medio, questa metrica indica mediamente di quanto il nostro modello si è sbagliato.\n",
    "\n",
    "$$ RMSE =  \\sqrt \\frac{\\sum_{i=1}^n (y_i-\\hat{y}_i)^2}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 - Coefficient of determination (Coefficiente di Determinazione)\n",
    "\n",
    "In pratica R2 (pronuciato R Squared) è una versione standardizzata del MSE che torna un punteggio compreso tra 0 e 1 per il train set, mentre per il test set può assumere anche valori negativi. Essendo una funzione ma di scoring, un suo valore maggiore indica una qualità migliore del modello, il suo valore può essere così interpretato:\n",
    "\n",
    "* R2_score < 0.3 il modello è inutile.\n",
    "* 0.3 < R2_score < 0.5 il modello è scarso.\n",
    "* 0.5 < R2_score < 0.7 il modello è discreto.\n",
    "* 0.7 < R2_score < 0.9 il modello è buono.\n",
    "* 0.9 < R2_score < 1 il modello è ottimo.\n",
    "* R2_score = 1 molto probabilmente c'è un errore nel modello.\n",
    "\n",
    "$$ R^2 = 1-\\frac{RSS}{SST} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dove RSS è la somma dei quadrati residui:\n",
    "$$ RSS = \\sum_{i=1}^{N}(Y_i-\\hat{Y}_i)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ed SST è la somma dei quadrati totali:\n",
    "$$ SST = \\sum_{i=1}^{N}(Y_i-\\bar{Y})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (Errore medio assoluto):  3.021670203672007\n",
      "Mean Squared Error (Errore quadratico assoluto):  17.18885239612977\n",
      "Root Mean Squared Error (Radice dell errore quadratico medio):  4.145944089846096\n",
      "Coefficient of determination (Coefficiente di Determinazione):  0.7783887838114685\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error (Errore medio assoluto): ',evaluation.meanAbsoluteError)\n",
    "print('Mean Squared Error (Errore quadratico assoluto): ', evaluation.meanSquaredError)\n",
    "print('Root Mean Squared Error (Radice dell errore quadratico medio): ', evaluation.rootMeanSquaredError)\n",
    "print('Coefficient of determination (Coefficiente di Determinazione): ', evaluation.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizzo del modello su nuovi dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora che abbiamo un modello addestrato e funzionante testiamolo su nuovi dati, mettiamo caso che un'agenzia immobiliare ci abbia mandato un file CSV con le proprietà di 10 abitazioni per la quale stimare il prezzo usando il modello addestrato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = spark.read.csv('houses.csv', header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+\n",
      "|0.05789|12.5| 6.07|   0|0.409|5.878|21.4| 6.498|  4|345|   18.9|396.21|  8.1|\n",
      "|0.13554|12.5| 6.07|   0|0.409|5.594|36.8| 6.498|  4|345|   18.9| 396.9|13.09|\n",
      "|0.08826| 0.0|10.81|   0|0.413|6.417| 6.6|5.2873|  4|305|   19.2|383.73| 6.72|\n",
      "|0.09164| 0.0|10.81|   0|0.413|6.065| 7.8|5.2873|  4|305|   19.2|390.91| 5.52|\n",
      "|0.19539| 0.0|10.81|   0|0.413|6.245| 6.2|5.2873|  4|305|   19.2|377.17| 7.54|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "houses.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check valori nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.select(houses['crim'].isNull() | \\\n",
    "              houses['zn'].isNull() | \\\n",
    "              houses['indus'].isNull() | \\\n",
    "              houses['chas'].isNull() | \\\n",
    "              houses['nox'].isNull() | \\\n",
    "              houses['rm'].isNull() | \\\n",
    "              houses['age'].isNull() | \\\n",
    "              houses['dis'].isNull() | \\\n",
    "              houses['rad'].isNull() | \\\n",
    "              houses['tax'].isNull() | \\\n",
    "              houses['ptratio'].isNull() | \\\n",
    "              houses['black'].isNull() | \\\n",
    "              houses['lstat'].isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non ci sono valori nulli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_ass = VectorAssembler(inputCols = houses.columns, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = v_ass.transform(houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+--------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|            features|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+--------------------+\n",
      "|0.05789|12.5| 6.07|   0|0.409|5.878|21.4| 6.498|  4|345|   18.9|396.21|  8.1|[0.05789,12.5,6.0...|\n",
      "|0.13554|12.5| 6.07|   0|0.409|5.594|36.8| 6.498|  4|345|   18.9| 396.9|13.09|[0.13554,12.5,6.0...|\n",
      "|0.08826| 0.0|10.81|   0|0.413|6.417| 6.6|5.2873|  4|305|   19.2|383.73| 6.72|[0.08826,0.0,10.8...|\n",
      "|0.09164| 0.0|10.81|   0|0.413|6.065| 7.8|5.2873|  4|305|   19.2|390.91| 5.52|[0.09164,0.0,10.8...|\n",
      "|0.19539| 0.0|10.81|   0|0.413|6.245| 6.2|5.2873|  4|305|   19.2|377.17| 7.54|[0.19539,0.0,10.8...|\n",
      "|0.07896| 0.0|12.83|   0|0.437|6.273| 6.0|4.2515|  5|398|   18.7|394.92| 6.78|[0.07896,0.0,12.8...|\n",
      "|0.09512| 0.0|12.83|   0|0.437|6.286|45.0|4.5026|  5|398|   18.7|383.23| 8.94|[0.09512,0.0,12.8...|\n",
      "|0.10153| 0.0|12.83|   0|0.437|6.279|74.5|4.0522|  5|398|   18.7|373.66|11.97|[0.10153,0.0,12.8...|\n",
      "|0.08707| 0.0|12.83|   0|0.437| 6.14|45.8|4.0905|  5|398|   18.7|386.96|10.27|[0.08707,0.0,12.8...|\n",
      "|0.04741| 0.0|11.93|   0|0.573| 6.03|80.8| 2.505|  1|273|   21.0| 396.9| 7.88|[0.04741,0.0,11.9...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "houses.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applichiamo la normalizzazione, assicurandoci di applicare la stessa trasformazione che abbiamo applicato agli esempi di addestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = scaler_model.transform(houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+--------------------+--------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|            features|     scaled_features|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+--------------------+--------------------+\n",
      "|0.05789|12.5| 6.07|   0|0.409|5.878|21.4| 6.498|  4|345|   18.9|396.21|  8.1|[0.05789,12.5,6.0...|[5.79634388521087...|\n",
      "|0.13554|12.5| 6.07|   0|0.409|5.594|36.8| 6.498|  4|345|   18.9| 396.9|13.09|[0.13554,12.5,6.0...|[0.00145240170302...|\n",
      "|0.08826| 0.0|10.81|   0|0.413|6.417| 6.6|5.2873|  4|305|   19.2|383.73| 6.72|[0.08826,0.0,10.8...|[9.20985880360672...|\n",
      "|0.09164| 0.0|10.81|   0|0.413|6.065| 7.8|5.2873|  4|305|   19.2|390.91| 5.52|[0.09164,0.0,10.8...|[9.58976267005973...|\n",
      "|0.19539| 0.0|10.81|   0|0.413|6.245| 6.2|5.2873|  4|305|   19.2|377.17| 7.54|[0.19539,0.0,10.8...|[0.00212510130086...|\n",
      "|0.07896| 0.0|12.83|   0|0.437|6.273| 6.0|4.2515|  5|398|   18.7|394.92| 6.78|[0.07896,0.0,12.8...|[8.16456118289281...|\n",
      "|0.09512| 0.0|12.83|   0|0.437|6.286|45.0|4.5026|  5|398|   18.7|383.23| 8.94|[0.09512,0.0,12.8...|[9.98090629587525...|\n",
      "|0.10153| 0.0|12.83|   0|0.437|6.279|74.5|4.0522|  5|398|   18.7|373.66|11.97|[0.10153,0.0,12.8...|[0.00107013748710...|\n",
      "|0.08707| 0.0|12.83|   0|0.437| 6.14|45.8|4.0905|  5|398|   18.7|386.96|10.27|[0.08707,0.0,12.8...|[9.07610566719278...|\n",
      "|0.04741| 0.0|11.93|   0|0.573| 6.03|80.8| 2.505|  1|273|   21.0| 396.9| 7.88|[0.04741,0.0,11.9...|[4.61841710401928...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "houses.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predizione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto possiamo utilizzare il nostro modello per eseguire la predizione del valore degli immobili."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B**: ovviamente il nostro modello considererà solo la colonna 'scaled_features' per eseguire la predizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+--------------------+--------------------+------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio| black|lstat|            features|     scaled_features|        prediction|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+--------------------+--------------------+------------------+\n",
      "|0.05789|12.5| 6.07|   0|0.409|5.878|21.4| 6.498|  4|345|   18.9|396.21|  8.1|[0.05789,12.5,6.0...|[5.79634388521087...| 21.54255438338617|\n",
      "|0.13554|12.5| 6.07|   0|0.409|5.594|36.8| 6.498|  4|345|   18.9| 396.9|13.09|[0.13554,12.5,6.0...|[0.00145240170302...| 18.16259090962968|\n",
      "|0.08826| 0.0|10.81|   0|0.413|6.417| 6.6|5.2873|  4|305|   19.2|383.73| 6.72|[0.08826,0.0,10.8...|[9.20985880360672...|26.100158528591376|\n",
      "|0.09164| 0.0|10.81|   0|0.413|6.065| 7.8|5.2873|  4|305|   19.2|390.91| 5.52|[0.09164,0.0,10.8...|[9.58976267005973...| 24.96409957353691|\n",
      "|0.19539| 0.0|10.81|   0|0.413|6.245| 6.2|5.2873|  4|305|   19.2|377.17| 7.54|[0.19539,0.0,10.8...|[0.00212510130086...|24.898058466120844|\n",
      "|0.07896| 0.0|12.83|   0|0.437|6.273| 6.0|4.2515|  5|398|   18.7|394.92| 6.78|[0.07896,0.0,12.8...|[8.16456118289281...|26.058668657213197|\n",
      "|0.09512| 0.0|12.83|   0|0.437|6.286|45.0|4.5026|  5|398|   18.7|383.23| 8.94|[0.09512,0.0,12.8...|[9.98090629587525...|24.570810233414722|\n",
      "|0.10153| 0.0|12.83|   0|0.437|6.279|74.5|4.0522|  5|398|   18.7|373.66|11.97|[0.10153,0.0,12.8...|[0.00107013748710...| 23.75777310470015|\n",
      "|0.08707| 0.0|12.83|   0|0.437| 6.14|45.8|4.0905|  5|398|   18.7|386.96|10.27|[0.08707,0.0,12.8...|[9.07610566719278...| 23.99936531344926|\n",
      "|0.04741| 0.0|11.93|   0|0.573| 6.03|80.8| 2.505|  1|273|   21.0| 396.9| 7.88|[0.04741,0.0,11.9...|[4.61841710401928...|   21.905385648477|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(houses).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infatti facendo come di seguito si ottiene lo stesso risultato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|     scaled_features|        prediction|\n",
      "+--------------------+------------------+\n",
      "|[5.79634388521087...| 21.54255438338617|\n",
      "|[0.00145240170302...| 18.16259090962968|\n",
      "|[9.20985880360672...|26.100158528591376|\n",
      "|[9.58976267005973...| 24.96409957353691|\n",
      "|[0.00212510130086...|24.898058466120844|\n",
      "|[8.16456118289281...|26.058668657213197|\n",
      "|[9.98090629587525...|24.570810233414722|\n",
      "|[0.00107013748710...| 23.75777310470015|\n",
      "|[9.07610566719278...| 23.99936531344926|\n",
      "|[4.61841710401928...|   21.905385648477|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(houses.select('scaled_features')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
